# @package _global_

defaults:
  - dreamer_v3
  - override /env: diambra
  - _self_

# Experiment
seed: 0
total_steps: 10000000
per_rank_batch_size: 8

# Environment
env:
  id: doapp
  num_envs: 4
  grayscale: True
  frame_stack: 1
  screen_size: 128
  reward_as_observation: True
  wrapper:
    attack_but_combination: True
    diambra_settings:
      characters: Kasumi
      difficulty: 4

# Checkpoint
checkpoint:
  every: 100000

# Buffer
buffer:
  checkpoint: True

# The CNN and MLP keys of the decoder are the same as those of the encoder by default
cnn_keys:
  encoder:
    - frame
mlp_keys:
  encoder:
    - reward
    - P1_actions_attack
    - P1_actions_move
    - P1_oppChar
    - P1_oppHealth
    - P1_oppSide
    - P1_oppWins
    - P1_ownChar
    - P1_ownHealth
    - P1_ownSide
    - P1_ownWins
    - stage
  decoder:
    - P1_actions_attack
    - P1_actions_move
    - P1_oppChar
    - P1_oppHealth
    - P1_oppSide
    - P1_oppWins
    - P1_ownChar
    - P1_ownHealth
    - P1_ownSide
    - P1_ownWins
    - stage

# Algorithm
algo:
  learning_starts: 65536
  train_every: 8
  dense_units: 768
  mlp_layers: 4
  world_model:
    encoder:
      cnn_channels_multiplier: 64
    recurrent_model:
      recurrent_state_size: 2048
    transition_model:
      hidden_size: 768
    representation_model:
      hidden_size: 768

# Metric
metric:
  log_every: 10000
